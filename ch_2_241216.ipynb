{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8513fc08",
   "metadata": {},
   "source": [
    "PyTorch에서 **텐서(Tensor)**는 데이터를 표현하는 기본 단위입니다. 이는 다차원 배열(n-dimensional array)로, 딥러닝 모델의 입력, 출력, 가중치 등을 표현하고 연산하는 데 사용됩니다.  \n",
    "텐서는 NumPy의 배열과 유사하지만, GPU 가속을 활용할 수 있다는 점에서 차별화됩니다.\n",
    "\n",
    "텐서의 특징\n",
    "1. 다차원 배열\n",
    "\n",
    "텐서는 스칼라(0차원)부터 벡터(1차원), 행렬(2차원), 고차원 배열까지 표현할 수 있습니다.\n",
    "예를 들어:\n",
    "스칼라(0D 텐서): 5\n",
    "\n",
    "벡터(1D 텐서): [1,2,3]\n",
    "\n",
    "행렬(2D 텐서): [[1,2],[3,4]]\n",
    "\n",
    "텐서 (3D 텐서): 여러 개의 행렬이 쌓여 있는 구조. 교재 35페이지 그림\n",
    "\n",
    "2. GPU 가속 가능\n",
    "\n",
    "텐서는 CPU뿐 아니라 GPU에서도 연산이 가능합니다.\n",
    "GPU에서 연산하려면 텐서를 .to('cuda') 또는 .cuda()를 사용하여 GPU로 옮깁니다.\n",
    "\n",
    "3. 자동 미분 지원\n",
    "\n",
    "텐서는 PyTorch의 자동 미분(Autograd) 기능과 연동됩니다. 이를 통해 텐서 연산의 기울기를 자동으로 계산할 수 있습니다.  \n",
    "예: requires_grad=True로 설정하면 텐서의 연산 기록을 저장하여 역전파(backpropagation)에 활용합니다.\n",
    "\n",
    "4. 다양한 자료형 지원\n",
    "\n",
    "PyTorch 텐서는 다양한 데이터 타입을 지원합니다 (e.g., float32, int64 등).\n",
    "예: torch.float, torch.int, torch.bool, torch.complex64 등.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "099ffddd",
   "metadata": {
    "id": "099ffddd"
   },
   "outputs": [],
   "source": [
    "##2.2.1 텐서 다루기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "934d9767",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "kZRX92aQVHLF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4692,
     "status": "ok",
     "timestamp": 1715838287186,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "kZRX92aQVHLF",
    "outputId": "51b480da-fda7-479a-8476-cb7ce1bc019a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파이토치에서 텐서 표현 \n",
    "import torch\n",
    "torch.cuda.is_available() # false이면 CPU 사용 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a92d22",
   "metadata": {},
   "source": [
    "PyTorch의 **연산 그래프(Computational Graph)**는 딥러닝 모델 학습 과정에서 **자동 미분(Autograd)**을 가능하게 하는 핵심 구조입니다. 연산 그래프는 모델의 파라미터가 어떻게 입력 데이터에서 출력으로 전달되는지, 그리고 손실 함수가 어떻게 계산되는지를 나타내는 데이터의 연산 경로를 추적하는 구조입니다.\n",
    "\n",
    "연산 그래프는 딥러닝에서 중요한 역전파(Backpropagation) 과정을 자동화하기 위해 필요합니다. 딥러닝의 목표는 손실(loss)을 최소화하기 위해 모델 파라미터(예: 가중치 \n",
    "𝑤와 편향 𝑏)를 학습시키는 것입니다. 이를 위해 **기울기(Gradient)**를 계산해야 합니다. \n",
    "\n",
    "\n",
    "1.기울기 자동 계산\n",
    "\n",
    "PyTorch는 연산 그래프를 기반으로 기울기를 자동으로 계산합니다. 사용자가 직접 복잡한 미분 공식을 유도할 필요가 없습니다.\n",
    "예를 들어, \n",
    "\n",
    "L=(wx+b) **2\n",
    " 라는 손실 함수가 있을 때, 연산 그래프를 통해 \n",
    "기울기 2wx를 자동으로 계산합니다.\n",
    "\n",
    "2. 효율적인 역전파\n",
    "\n",
    "연산 그래프는 **체인 룰(Chain Rule)**을 적용하여 입력부터 출력까지 모든 연산의 미분을 효율적으로 계산합니다.\n",
    "역전파 과정에서 그래프의 각 연산 노드에서 기울기를 계산하고 전파합니다.\n",
    "\n",
    "3. 동적 계산 지원\n",
    "PyTorch는 **동적 연산 그래프(Dynamic Computational Graph)**를 사용합니다. 즉, 연산이 수행될 때 그래프가 실시간으로 생성됩니다.\n",
    "이런 동적 특성 덕분에 조건문, 반복문 등의 구조적인 변화가 있는 모델도 쉽게 정의할 수 있습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0009e0b",
   "metadata": {},
   "source": [
    "연산 그래프의 용도\n",
    "1. 기울기 계산 (자동 미분)\n",
    "연산 그래프를 사용하면, 모델의 파라미터에 대한 손실 함수의 기울기를 자동으로 계산할 수 있습니다. PyTorch에서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "29182545",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(28.)\n",
      "tensor(42.)\n",
      "tensor(14.)\n"
     ]
    }
   ],
   "source": [
    "## 연산 그래프가 각 줄이 연결된다\n",
    "    \n",
    "import torch\n",
    "\n",
    "# requires_grad=True 설정된 텐서\n",
    "x = torch.tensor(2.0, requires_grad=True)\n",
    "w = torch.tensor(3.0, requires_grad=True)\n",
    "b = torch.tensor(1.0, requires_grad=True)\n",
    "\n",
    "# 연산 정의\n",
    "y = w * x + b\n",
    "loss = y ** 2  # 손실 함수\n",
    "\n",
    "# 역전파\n",
    "loss.backward()\n",
    "\n",
    "# 각 텐서의 기울기 출력\n",
    "print(w.grad)  # dy/dw\n",
    "print(x.grad)  # dy/dx\n",
    "print(b.grad)  # dy/db\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fcc9464",
   "metadata": {},
   "source": [
    "2. 딥러닝 학습(역전파 기반의 가중치 업데이트)\n",
    "연산 그래프는 딥러닝 모델의 학습 과정에서 손실 함수의 기울기를 계산하고, 이를 기반으로 가중치를 업데이트합니다.\n",
    "\n",
    "1.순전파(Forward Pass):\n",
    "입력 데이터를 연산 그래프를 따라 계산하여 출력(예측값)을 생성.\n",
    "2. 손실 계산:\n",
    "출력값과 실제 값 사이의 손실을 계산.\n",
    "3. 역전파(Backward Pass):\n",
    "연산 그래프를 따라 손실 함수의 기울기를 계산.\n",
    "4. 가중치 업데이트:\n",
    "기울기를 사용하여 경사하강법(Gradient Descent)으로 가중치를 업데이트."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0054917d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimizer를 활용한 가중치 업데이트\n",
    "optimizer = torch.optim.SGD([w, b], lr=0.01)\n",
    "\n",
    "# 역전파 후 가중치 업데이트\n",
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4661d2",
   "metadata": {},
   "source": [
    "2.2.1 텐서 다루기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "805e1388",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<built-in method type of Tensor object at 0x00000223E584D950>\n",
      "------------------------\n",
      "------------------------\n",
      "tensor([[1., 2.],\n",
      "        [3., 4.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "import torch # GPU를 지원하는 텐서 패키지\n",
    "t = torch.tensor([[1, 2], [3, 4]])\n",
    "print(t.type) # 텐서 객체를 만든다\n",
    "print('------------------------')\n",
    "#print(torch.tensor([[1,2],[3,4]], device=\"cuda:0\")) # GPU가 없다면 오류가 발생하므로 주석 처리하였습니다.\n",
    "print('------------------------')\n",
    "\n",
    "print(torch.tensor([[1,2],[3,4]], dtype=torch.float64))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "13955c29",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 313,
     "status": "ok",
     "timestamp": 1715838722984,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "13955c29",
    "outputId": "9bb7554d-bda0-4672-d1fb-1c21455ac0be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "[[1 2]\n",
      " [3 4]]\n",
      "cpu\n",
      "------------------------\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n",
      "cpu\n",
      "[[1 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "temp = torch.tensor([[1,2],[3,4]])\n",
    "print(temp)\n",
    "print(temp.numpy()) # 텐서를 ndarray로 변환\n",
    "print(temp.device) #device 속성을 확인\n",
    "print('------------------------')\n",
    "#temp = torch.tensor([[1,2],[3,4]], device=\"cuda:0\") #GPU가 없다면 오류가 발생하므로 주석 처리하였습니다.\n",
    "print(temp) #cpu tensor와 구분\n",
    "print(temp.device)  # 출력: cuda:0 // gpu 활성화 안 하면 cpu\n",
    "#print(temp.numpy()) # cuda tensor > ndarray로 변환 안된다\n",
    "#temp = torch.tensor([[1,2],[3,4]], device=\"cuda:0\")# GPU\n",
    "print(temp.to(\"cpu\").numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8018550e",
   "metadata": {},
   "source": [
    "텐서의 인덱스 조작 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4ceaaed8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 307,
     "status": "ok",
     "timestamp": 1715838503672,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "4ceaaed8",
    "outputId": "39ad090a-b964-4636-c23a-851626c9ffb8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3., 4., 5., 6., 7.])\n",
      "tensor(1.) tensor(2.) tensor(7.)\n",
      "------------------------\n",
      "tensor([3., 4., 5.]) tensor([5., 6.])\n"
     ]
    }
   ],
   "source": [
    "temp = torch.FloatTensor([1, 2, 3, 4, 5, 6, 7])\n",
    "print(temp)\n",
    "print(temp[0], temp[1], temp[-1])\n",
    "print('------------------------')\n",
    "print(temp[2:5], temp[4:-1]) #넘파이 슬라이싱과 같다 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "h7Qp_dpVynFf",
   "metadata": {
    "id": "h7Qp_dpVynFf"
   },
   "source": [
    "텐서 연산 및 차원 조작"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "35d9751c",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 924,
     "status": "ok",
     "timestamp": 1715730427854,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "35d9751c",
    "outputId": "4fea9e46-2239-4f0f-a5b8-89a5e8790bff"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2, 2, 3])\n",
      "tensor([ 3,  8, 18])\n"
     ]
    }
   ],
   "source": [
    "v = torch.tensor([1, 2, 3])\n",
    "w = torch.tensor([3, 4, 6])\n",
    "print(w - v) # 벡터 연산\n",
    "print(w * v) # 벡터 연산 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "50d75b43",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 307,
     "status": "ok",
     "timestamp": 1715838843238,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "50d75b43",
    "outputId": "2f5b2f54-a9ed-4aa3-bbbb-e600bf538c7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2])\n",
      "------------------------\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n",
      "------------------------\n",
      "torch.Size([4])\n",
      "tensor([1, 2, 3, 4])\n",
      "------------------------\n",
      "tensor([[1, 2, 3, 4]])\n",
      "------------------------\n",
      "tensor([[1],\n",
      "        [2],\n",
      "        [3],\n",
      "        [4]])\n"
     ]
    }
   ],
   "source": [
    "temp = torch.tensor([\n",
    "    [1, 2], [3, 4]\n",
    "])\n",
    "\n",
    "print(temp.shape)\n",
    "print('------------------------')\n",
    "print(temp.view(4,1)) # (4,1)\n",
    "print('------------------------')\n",
    "t2= temp.view(-1) # [4] - 넘파이의 reshape()과 유사\n",
    "print(t2.shape)\n",
    "print(temp.view(-1)) # (4,) - 1차원 벡터로 변환 \n",
    "print('------------------------')\n",
    "print(temp.view(1, -1)) # (1,4) > (1, ?)로 변환\n",
    "print('------------------------')\n",
    "print(temp.view(-1, 1)) # (4,1) > (?, 1)로 변환"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "Y1P77eHuSfX8",
   "metadata": {
    "id": "Y1P77eHuSfX8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "data=pd.read_csv('./book/chap09/data/class2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "glcxHZezUgJS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 307,
     "status": "ok",
     "timestamp": 1715839595705,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "glcxHZezUgJS",
    "outputId": "86319734-952a-4997-aec2-64dbbf1ed66c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0      id tissue class class2      x      y      r\n",
      "0           0  mdb000      C  CIRC      N  535.0  475.0  192.0\n",
      "1           1  mdb001      A  CIRA      N  433.0  268.0   58.0\n",
      "2           2  mdb002      A  CIRA      I    NaN    NaN    NaN\n",
      "3           3  mdb003      C  CIRC      B    NaN    NaN    NaN\n",
      "4           4  mdb004      F  CIRF      I  488.0  145.0   29.0\n",
      "5           5  mdb005      F  CIRF      B  544.0  178.0   26.0\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "38LHO7H3U6WV",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 633,
     "status": "ok",
     "timestamp": 1715773184157,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "38LHO7H3U6WV",
    "outputId": "0c8b686f-1352-44be-9d13-6de856983f5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[535.],\n",
      "        [433.],\n",
      "        [ nan],\n",
      "        [ nan],\n",
      "        [488.],\n",
      "        [544.]])\n"
     ]
    }
   ],
   "source": [
    "#왜 unsqueeze()를 하는가?\n",
    "x=torch.from_numpy(data['x'].values).unsqueeze(dim=1).float()\n",
    "y=torch.from_numpy(data['y'].values).unsqueeze(dim=1).float()\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a2a681",
   "metadata": {},
   "source": [
    "unsqueeze()는 PyTorch에서 텐서의 차원(dimension)을 추가하는 데 사용되는 메서드입니다.  \n",
    "즉, 기존 텐서의 특정 위치에 크기가 1인 차원을 삽입하여 텐서의 모양(shape)을 변경합니다.\n",
    "\n",
    "tensor.unsqueeze(dim)\n",
    "dim: 새로 추가할 차원의 위치를 지정합니다. 음수를 사용하면 뒤에서부터 차원을 계산합니다.  \n",
    "결과: 지정된 위치에 크기가 1인 차원이 추가된 새로운 텐서를 반환합니다.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "3ccfe08c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3])\n",
      "torch.Size([3, 1])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x = torch.tensor([1, 2, 3])  # x의 shape: (3,)\n",
    "x_unsqueezed = x.unsqueeze(0)  # dim=0에 차원을 추가\n",
    "print(x_unsqueezed.shape)  # 출력: torch.Size([1, 3])\n",
    "\n",
    "x_unsqueezed = x.unsqueeze(1)  # dim=1에 차원을 추가\n",
    "print(x_unsqueezed.shape)  # 출력: torch.Size([3, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251b2afe",
   "metadata": {},
   "source": [
    "x.unsqueeze(0): (3,) → (1, 3) (배열의 맨 앞에 차원이 추가됨).\n",
    "x.unsqueeze(1): (3,) → (3, 1) (배열의 두 번째 차원에 추가됨)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "4764ea74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_unsqueezed = x.unsqueeze(2)  Dimension out of range (expected to be in range of [-2, 1], but got 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "c6e04895",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[535.],\n",
      "        [433.],\n",
      "        [ nan],\n",
      "        [ nan],\n",
      "        [488.],\n",
      "        [544.]]) <built-in method type of Tensor object at 0x00000223E584EBC0>\n"
     ]
    }
   ],
   "source": [
    "x = torch.from_numpy(data['x'].values).unsqueeze(dim=1).float()\n",
    "print(x, x.type)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97293322",
   "metadata": {},
   "source": [
    "1. torch.from_numpy(data['x'].values)\n",
    "data['x'].values: NumPy 배열 형태의 데이터를 PyTorch 텐서로 변환.\n",
    "예를 들어, data['x'].values의 형태가 (N,)라고 가정.\n",
    "\n",
    "2. .unsqueeze(dim=1)\n",
    "dim=1에 크기가 1인 차원을 추가.\n",
    "기존 텐서의 shape이 (N,)라면, unsqueeze(dim=1)의 결과는 (N, 1)이 됩니다.  \n",
    "이 과정은 일반적으로 딥러닝 모델에 입력 데이터를 맞추기 위해 사용됩니다.\n",
    "(예: 입력 데이터가 2D 형태인 (N, 1)이 되어야 하는 경우)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b3634af",
   "metadata": {},
   "source": [
    "왜 unsqueeze(dim=1)이 필요한가?  \n",
    "많은 딥러닝 모델은 2D 입력을 필요로 합니다. 특히, 선형 회귀나 MLP(Multi-Layer Perceptron) 같은 모델에서는 각 입력 데이터가 (N, D) 형태(즉, N개의 샘플에 대해 D차원 특성 벡터)여야 합니다.\n",
    "\n",
    "예를 들어:  \n",
    "원래 데이터가 1D 텐서: [x1, x2, x3, ...] (shape: (N,)).  \n",
    "이를 2D로 변경: [[x1], [x2], [x3], ...] (shape: (N, 1)).  \n",
    "unsqueeze(dim=1)을 사용하여 2D 텐서로 확장합니다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401223d8",
   "metadata": {},
   "source": [
    "covtype.csv는 Covertype 데이터셋으로, 미국 콜로라도주의 국립공원의 토양 및 식생 유형을 예측하기 위한 표준 데이터셋입니다.  \n",
    "이 데이터셋은 UCI 머신러닝 저장소에 공개되어 있으며, CSV 형식으로 다운로드할 수 있습니다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a041531",
   "metadata": {},
   "source": [
    "Custom dataset을 만들어서 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9ZRkBKGQWuti",
   "metadata": {
    "id": "9ZRkBKGQWuti"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self,csv_file):\n",
    "      self.label=pd.read_csv(csv_file)\n",
    "\n",
    "    def __len__(self):\n",
    "      return len(self.label)\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "      sample=torch.tensor(self.label.iloc[idx,0:3]).int()\n",
    "      label=torch.tensor(self.label.iloc[idx,3]).int()\n",
    "      return sample, label\n",
    "\n",
    "tensor_dataset=CustomDataset('covtype.csv')\n",
    "dataset=DataLoader(tensor_dataset,batch_size=4,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "LeTag_R0E7B3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 291
    },
    "executionInfo": {
     "elapsed": 353,
     "status": "ok",
     "timestamp": 1715840738211,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "LeTag_R0E7B3",
    "outputId": "59f2ba07-ee93-4424-97ce-5d0b91772bd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1;31mInit signature:\u001b[0m\n",
      "\u001b[0mDataLoader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdataset\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataset\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0m_T_co\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mbatch_size\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mshuffle\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0msampler\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSampler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mbatch_sampler\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msampler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSampler\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mIterable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mnum_workers\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mcollate_fn\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mList\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m~\u001b[0m\u001b[0m_T\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mpin_memory\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mdrop_last\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mfloat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mworker_init_fn\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mCallable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNoneType\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mmultiprocessing_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mgenerator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[1;33m*\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mprefetch_factor\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mpersistent_workers\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m    \u001b[0mpin_memory_device\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m''\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\n",
      "\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mDocstring:\u001b[0m     \n",
      "Data loader combines a dataset and a sampler, and provides an iterable over the given dataset.\n",
      "\n",
      "The :class:`~torch.utils.data.DataLoader` supports both map-style and\n",
      "iterable-style datasets with single- or multi-process loading, customizing\n",
      "loading order and optional automatic batching (collation) and memory pinning.\n",
      "\n",
      "See :py:mod:`torch.utils.data` documentation page for more details.\n",
      "\n",
      "Args:\n",
      "    dataset (Dataset): dataset from which to load the data.\n",
      "    batch_size (int, optional): how many samples per batch to load\n",
      "        (default: ``1``).\n",
      "    shuffle (bool, optional): set to ``True`` to have the data reshuffled\n",
      "        at every epoch (default: ``False``).\n",
      "    sampler (Sampler or Iterable, optional): defines the strategy to draw\n",
      "        samples from the dataset. Can be any ``Iterable`` with ``__len__``\n",
      "        implemented. If specified, :attr:`shuffle` must not be specified.\n",
      "    batch_sampler (Sampler or Iterable, optional): like :attr:`sampler`, but\n",
      "        returns a batch of indices at a time. Mutually exclusive with\n",
      "        :attr:`batch_size`, :attr:`shuffle`, :attr:`sampler`,\n",
      "        and :attr:`drop_last`.\n",
      "    num_workers (int, optional): how many subprocesses to use for data\n",
      "        loading. ``0`` means that the data will be loaded in the main process.\n",
      "        (default: ``0``)\n",
      "    collate_fn (Callable, optional): merges a list of samples to form a\n",
      "        mini-batch of Tensor(s).  Used when using batched loading from a\n",
      "        map-style dataset.\n",
      "    pin_memory (bool, optional): If ``True``, the data loader will copy Tensors\n",
      "        into device/CUDA pinned memory before returning them.  If your data elements\n",
      "        are a custom type, or your :attr:`collate_fn` returns a batch that is a custom type,\n",
      "        see the example below.\n",
      "    drop_last (bool, optional): set to ``True`` to drop the last incomplete batch,\n",
      "        if the dataset size is not divisible by the batch size. If ``False`` and\n",
      "        the size of dataset is not divisible by the batch size, then the last batch\n",
      "        will be smaller. (default: ``False``)\n",
      "    timeout (numeric, optional): if positive, the timeout value for collecting a batch\n",
      "        from workers. Should always be non-negative. (default: ``0``)\n",
      "    worker_init_fn (Callable, optional): If not ``None``, this will be called on each\n",
      "        worker subprocess with the worker id (an int in ``[0, num_workers - 1]``) as\n",
      "        input, after seeding and before data loading. (default: ``None``)\n",
      "    multiprocessing_context (str or multiprocessing.context.BaseContext, optional): If\n",
      "        ``None``, the default `multiprocessing context`_ of your operating system will\n",
      "        be used. (default: ``None``)\n",
      "    generator (torch.Generator, optional): If not ``None``, this RNG will be used\n",
      "        by RandomSampler to generate random indexes and multiprocessing to generate\n",
      "        ``base_seed`` for workers. (default: ``None``)\n",
      "    prefetch_factor (int, optional, keyword-only arg): Number of batches loaded\n",
      "        in advance by each worker. ``2`` means there will be a total of\n",
      "        2 * num_workers batches prefetched across all workers. (default value depends\n",
      "        on the set value for num_workers. If value of num_workers=0 default is ``None``.\n",
      "        Otherwise, if value of ``num_workers > 0`` default is ``2``).\n",
      "    persistent_workers (bool, optional): If ``True``, the data loader will not shut down\n",
      "        the worker processes after a dataset has been consumed once. This allows to\n",
      "        maintain the workers `Dataset` instances alive. (default: ``False``)\n",
      "    pin_memory_device (str, optional): the device to :attr:`pin_memory` to if ``pin_memory`` is\n",
      "        ``True``.\n",
      "\n",
      "\n",
      ".. warning:: If the ``spawn`` start method is used, :attr:`worker_init_fn`\n",
      "             cannot be an unpicklable object, e.g., a lambda function. See\n",
      "             :ref:`multiprocessing-best-practices` on more details related\n",
      "             to multiprocessing in PyTorch.\n",
      "\n",
      ".. warning:: ``len(dataloader)`` heuristic is based on the length of the sampler used.\n",
      "             When :attr:`dataset` is an :class:`~torch.utils.data.IterableDataset`,\n",
      "             it instead returns an estimate based on ``len(dataset) / batch_size``, with proper\n",
      "             rounding depending on :attr:`drop_last`, regardless of multi-process loading\n",
      "             configurations. This represents the best guess PyTorch can make because PyTorch\n",
      "             trusts user :attr:`dataset` code in correctly handling multi-process\n",
      "             loading to avoid duplicate data.\n",
      "\n",
      "             However, if sharding results in multiple workers having incomplete last batches,\n",
      "             this estimate can still be inaccurate, because (1) an otherwise complete batch can\n",
      "             be broken into multiple ones and (2) more than one batch worth of samples can be\n",
      "             dropped when :attr:`drop_last` is set. Unfortunately, PyTorch can not detect such\n",
      "             cases in general.\n",
      "\n",
      "             See `Dataset Types`_ for more details on these two types of datasets and how\n",
      "             :class:`~torch.utils.data.IterableDataset` interacts with\n",
      "             `Multi-process data loading`_.\n",
      "\n",
      ".. warning:: See :ref:`reproducibility`, and :ref:`dataloader-workers-random-seed`, and\n",
      "             :ref:`data-loading-randomness` notes for random seed related questions.\n",
      "\n",
      ".. _multiprocessing context:\n",
      "    https://docs.python.org/3/library/multiprocessing.html#contexts-and-start-methods\n",
      "\u001b[1;31mFile:\u001b[0m           c:\\devtool\\anaconda3\\envs\\torch_book\\lib\\site-packages\\torch\\utils\\data\\dataloader.py\n",
      "\u001b[1;31mType:\u001b[0m           type\n",
      "\u001b[1;31mSubclasses:\u001b[0m     "
     ]
    }
   ],
   "source": [
    "DataLoader?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "0a3a20a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 실행 금지!!! - 굉장히 오래 걸린다 \n",
    "# dataloader는 다음과 같이 반복실행하는 기능 => 실행시키지 않아야 함\n",
    "# for i,data in enumerate(dataset,0):\n",
    "#     print(i,end='')\n",
    "#     batch=data[0]\n",
    "#     print(batch.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf6aaf0",
   "metadata": {},
   "source": [
    "파이토치에서 제공하는 데이터셋 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "rUmwfd6_kvCq",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5807,
     "status": "ok",
     "timestamp": 1715773231058,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "rUmwfd6_kvCq",
    "outputId": "a582e146-cbd9-4a28-953a-3b05499a9b36"
   },
   "outputs": [],
   "source": [
    "# pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "7423e510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a99daa6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1\n",
      "0.20.1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision # 내장된 이미지 데이터 세트\n",
    "\n",
    "print(torch.__version__)         # PyTorch 버전 출력\n",
    "print(torchvision.__version__)   # torchvision 버전 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "V6n5xvrSk7m6",
   "metadata": {
    "id": "V6n5xvrSk7m6"
   },
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms\n",
    "\n",
    "mnist_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,),(1.0,))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "fTpwWvg5liXj",
   "metadata": {
    "id": "fTpwWvg5liXj"
   },
   "outputs": [],
   "source": [
    "# from torchvision.datasets import MNIST\n",
    "# download_root = './book/chap02/data/MNIST_DATASET'\n",
    "\n",
    "# train_dataset = MNIST(download_root, transform=mnist_transform, train=True, download=True)\n",
    "# valid_dataset = MNIST(download_root, transform=mnist_transform, train=False, download=True)\n",
    "# test_dataset = MNIST(download_root, transform=mnist_transform, train=False, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KD-uI2jmm-Vo",
   "metadata": {
    "id": "KD-uI2jmm-Vo"
   },
   "source": [
    "2.2.3 모델 정의\n",
    "\n",
    "단순 신경망 정의하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1EZYoRRPmylO",
   "metadata": {
    "id": "1EZYoRRPmylO"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "model = nn.Linear(in_features=1, out_features=1, bias=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0690a8",
   "metadata": {},
   "source": [
    "torch.nn.Module은 PyTorch에서 신경망 모델을 정의할 때 사용하는 기본 클래스입니다.  \n",
    "이 클래스는 모델의 구조를 정의하고, 모델을 학습하고 평가할 때 필요한 메소드를 제공합니다.  \n",
    "forward() 메소드는 모델의 전방향 패스(forward pass) 를 정의하는 데 사용됩니다.  \n",
    "즉, 데이터를 모델에 통과시켜 예측을 만드는 과정입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "u5jtlKZrm602",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 516,
     "status": "ok",
     "timestamp": 1715843179197,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "u5jtlKZrm602",
    "outputId": "3a281f83-4c2c-4697-8571-9dbc26b27ac9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0026]], grad_fn=<SigmoidBackward0>)\n",
      "[[0.0025626765564084053]]\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module): # MLP의 superclass가 nn.Module이다\n",
    "  def __init__(self, inputs):\n",
    "    super(MLP, self).__init__()\n",
    "    self.layer = nn.Linear(inputs, 1)\n",
    "    self.activation = nn.Sigmoid()\n",
    "\n",
    "  def forward(self, X):# forward 메소드는 모델이 입력 데이터를 어떻게 처리할지 정의\n",
    "    X = self.layer(X)\n",
    "    X = self.activation(X)\n",
    "    return X\n",
    "\n",
    "data = torch.tensor([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=torch.float32).unsqueeze(0)  # 텐서 크기를 바꾸어 실행\n",
    "model = MLP(len(data[0]))  # 입력의 차원을 데이터의 길이로\n",
    "output = model(data) # 학습 객체: forward가 data를 x로 받아서 처리 // fit하는거임\n",
    "print(output)\n",
    "print(output.tolist())  # 모델의 출력을 리스트로"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "Q39CVdKV2DRE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 277,
     "status": "ok",
     "timestamp": 1715773256089,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "Q39CVdKV2DRE",
    "outputId": "b69d5165-01d3-422e-9821-356a240faf63"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.1236, 0.0795, 0.0000, 0.1195, 0.2510, 0.1440, 0.3234, 0.2777,\n",
      "         0.0000],\n",
      "        [0.0000, 0.0923, 0.0858, 0.0000, 0.2422, 0.2754, 0.1422, 0.1530, 0.4400,\n",
      "         0.0000],\n",
      "        [0.0000, 0.1128, 0.0989, 0.0000, 0.2942, 0.4217, 0.2478, 0.3632, 0.2501,\n",
      "         0.0000]], grad_fn=<ReluBackward0>)\n"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(MLP, self).__init__()\n",
    "    self.layer1 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=3, out_channels=64, kernel_size=5),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(2))\n",
    "\n",
    "    self.layer2 = nn.Sequential(\n",
    "        nn.Conv2d(in_channels=64, out_channels=30, kernel_size=5),\n",
    "        nn.ReLU(inplace=True),\n",
    "        nn.MaxPool2d(2))\n",
    "\n",
    "    self.layer3 = nn.Sequential(\n",
    "        nn.Linear(in_features=30*5*5, out_features=10, bias=True),\n",
    "        nn.ReLU(inplace=True))\n",
    "\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = self.layer1(x)\n",
    "    x = self.layer2(x)\n",
    "    x = x.view(x.shape[0],-1)\n",
    "    x = self.layer3(x)\n",
    "    return x\n",
    "\n",
    "model = MLP()\n",
    "data = torch.randn(3, 3, 32, 32)  # 3개의 이미지를 생성합니다. 각 이미지는 3채널(RGB)이며, 크기는 32x32입니다.\n",
    "model = MLP()  # 입력의 차원을 데이터의 길이로\n",
    "output = model(data)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec339731",
   "metadata": {},
   "source": [
    "forward() 메소드를 정의하면, 모델을 호출하는 것만으로 이 메소드가 자동으로 실행됩니다.  \n",
    "예를 들어, model(x)와 같이 호출하면 forward() 메소드가 실행됩니다.\n",
    "\n",
    "nn.Module 클래스는 PyTorch에서 신경망 모델을 정의할 때 사용하는 기본 클래스입니다.  \n",
    "이 클래스는 모델의 구조(Layer 정의)와 동작(Forward Pass)을 정의할 수 있는 메소드들을 제공합니다.  \n",
    "forward() 메소드는 바로 이 동작을 정의하는 곳입니다.\n",
    "\n",
    "우리가 `model(input_data)`라고 호출할 때, PyTorch는 자동으로 `forward()` 메소드를 실행합니다.  \n",
    "이 호출은 다음과 같은 일련의 과정을 통해 이루어집니다:\n",
    "\n",
    "output = model(input_data)\n",
    "\n",
    "모델을 호출하는 model(input_data)는 `__call__()` 메소드를 트리거합니다.  \n",
    "nn.Module은 `__call__()` 메소드를 오버라이드(재정의)한 클래스입니다. 이 메소드는 실제로 `forward()` 메소드를 호출합니다.  \n",
    "  \n",
    "`nn.Module.__call__(self, *input, **kwargs)`는 아래와 같은 작업을 수행합니다:  \n",
    "forward() 메소드 호출: `__call__()`는 인스턴스가 호출될 때, 내부적으로 forward() 메소드를 호출합니다.  \n",
    "추가적인 작업: `__call__()` 메소드는 추후 필요에 따라 여러 후처리 작업을 수행할 수 있습니다 (예: training 모드에서의 동작 제어 등).  \n",
    "따라서, `model(input_data)`는 사실 `model.__call__(input_data)` 와 같으며, 내부적으로 `model.forward(input_data)` 를 실행합니다.  \n",
    "\n",
    "`forward()` 메소드는 `model(input_data)`에서 자동으로 호출되며, 여기서 정의된 모델의 연산 흐름을 처리합니다.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "4w8Llw5iFWMR",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 288,
     "status": "ok",
     "timestamp": 1715773262923,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "4w8Llw5iFWMR",
    "outputId": "24a8507a-8e6f-46bc-8ce6-6639136a09ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 1])\n",
      "tensor([[-0.0714],\n",
      "        [-0.0997],\n",
      "        [-0.1756],\n",
      "        [-0.1459],\n",
      "        [-0.1249],\n",
      "        [-0.0775],\n",
      "        [-0.0705],\n",
      "        [-0.1412],\n",
      "        [-0.0757],\n",
      "        [-0.1606]], grad_fn=<AddmmBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "def MLP(in_features=1, hidden_features=20, out_features=1):\n",
    "    hidden = nn.Linear(in_features=in_features, out_features=hidden_features, bias=True)\n",
    "    activation = nn.ReLU()\n",
    "    output = nn.Linear(in_features=hidden_features, out_features=out_features, bias=True)\n",
    "    net = nn.Sequential(hidden, activation, output)\n",
    "    return net\n",
    "\n",
    "# 데이터 준비\n",
    "data = torch.randn(10, 1)  # 예시로 10개의 데이터 포인트를 생성합니다.\n",
    "print(data.shape)\n",
    "# 모델 생성\n",
    "model = MLP()\n",
    "\n",
    "# 모델 호출\n",
    "output = model(data) #data.shape = (10,1)이므로 in_features는 10이 되고 10개의 입력을 받아들임\n",
    "#  model(data)를 호출하면, MLP 클래스의 forward 메서드가 호출되면서\n",
    "##입력 데이터가 전달되고, 해당 입력 데이터에 대한 연산이 수행되어 출력이 생성됩니다.\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NKD_8M96Qxp4",
   "metadata": {
    "id": "NKD_8M96Qxp4"
   },
   "source": [
    "2.2.4 모델 파라미터 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "Fg5TyyvBQ2Zt",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "executionInfo": {
     "elapsed": 272,
     "status": "error",
     "timestamp": 1715773784970,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "Fg5TyyvBQ2Zt",
    "outputId": "7c50a3e6-e570-4d80-f70d-45cf122fdb77"
   },
   "outputs": [],
   "source": [
    "# ### 교재 56페이지: 모델 파라미터 코드\n",
    "# from torch.optim import optimizer\n",
    "# criterion = torch.nn.MSELoss()\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "# scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer=optimizer,\n",
    "#                                               lr_lambda=lambda epoch: 0.95**epoch)\n",
    "# batch_size = 32\n",
    "\n",
    "# # DataLoader 정의\n",
    "# dataloader = DataLoader(tensor_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# for epoch in range(1, 100+1):\n",
    "#     model.train()\n",
    "#     for x, y in dataloader:\n",
    "#         x = x.float()\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(x)\n",
    "#         loss = criterion(outputs, y)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "GZ8ZUtIkSr6o",
   "metadata": {
    "id": "GZ8ZUtIkSr6o"
   },
   "outputs": [],
   "source": [
    "from torch.optim import optimizer\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.optim import SGD, lr_scheduler\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 데이터셋과 데이터로더를 정의해야 합니다.\n",
    "# 예를 들어, 단순한 데이터셋을 만들고 데이터로더를 생성할 수 있습니다.\n",
    "class SimpleDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data):\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "\n",
    "# 예제 데이터를 생성합니다.\n",
    "data = [(torch.randn(1), torch.randn(1)) for _ in range(100)]\n",
    "# 데이터셋을 생성합니다.\n",
    "dataset = SimpleDataset(data)\n",
    "# 데이터로더를 생성합니다.\n",
    "dataloader = DataLoader(dataset, batch_size=10, shuffle=True)\n",
    "\n",
    "# 모델을 생성합니다.\n",
    "def MLP(in_features=1, hidden_features=20, out_features=1):\n",
    "    hidden = nn.Linear(in_features=in_features, out_features=hidden_features, bias=True)\n",
    "    activation = nn.ReLU()\n",
    "    output = nn.Linear(in_features=hidden_features, out_features=out_features, bias=True)\n",
    "    net = nn.Sequential(hidden, activation, output)\n",
    "    return net\n",
    "\n",
    "# 모델을 생성합니다.\n",
    "model = MLP()\n",
    "\n",
    "# 손실 함수를 정의합니다.\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# 옵티마이저를 정의합니다.\n",
    "optimizer = SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# 스케줄러를 정의합니다.\n",
    "scheduler = lr_scheduler.LambdaLR(optimizer, lr_lambda=lambda epoch: 0.95**epoch)\n",
    "\n",
    "# 모델 훈련 교재 57페이지\n",
    "for epoch in range(1, 100+1):\n",
    "    for x, y in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        loss = criterion(model(x), y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "# 학습 후의 모델을 사용하여 예측을 수행할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "uX4zgvP4S-tG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 337,
     "status": "ok",
     "timestamp": 1715845783636,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "uX4zgvP4S-tG",
    "outputId": "295f3bfd-97fc-4479-ba50-816465385334"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(tensor([0.0403]), tensor([0.2758])), (tensor([-0.4849]), tensor([-1.3237])), (tensor([-1.1763]), tensor([-0.6853])), (tensor([-0.6344]), tensor([-2.0582])), (tensor([-0.9957]), tensor([-0.9869])), (tensor([0.6168]), tensor([0.5444])), (tensor([-0.5327]), tensor([-0.7169])), (tensor([-0.8424]), tensor([-1.2369])), (tensor([-1.3675]), tensor([1.9471])), (tensor([-1.1127]), tensor([0.6131]))]\n",
      "Input: tensor([0.0403])\n",
      "Actual Output: tensor([0.2758])\n",
      "Predicted Output: tensor([-0.0226])\n",
      "Input: tensor([-0.4849])\n",
      "Actual Output: tensor([-1.3237])\n",
      "Predicted Output: tensor([-0.0082])\n",
      "Input: tensor([-1.1763])\n",
      "Actual Output: tensor([-0.6853])\n",
      "Predicted Output: tensor([0.0796])\n",
      "Input: tensor([-0.6344])\n",
      "Actual Output: tensor([-2.0582])\n",
      "Predicted Output: tensor([-0.0057])\n",
      "Input: tensor([-0.9957])\n",
      "Actual Output: tensor([-0.9869])\n",
      "Predicted Output: tensor([0.0479])\n",
      "Input: tensor([0.6168])\n",
      "Actual Output: tensor([0.5444])\n",
      "Predicted Output: tensor([-0.0315])\n",
      "Input: tensor([-0.5327])\n",
      "Actual Output: tensor([-0.7169])\n",
      "Predicted Output: tensor([-0.0069])\n",
      "Input: tensor([-0.8424])\n",
      "Actual Output: tensor([-1.2369])\n",
      "Predicted Output: tensor([0.0177])\n",
      "Input: tensor([-1.3675])\n",
      "Actual Output: tensor([1.9471])\n",
      "Predicted Output: tensor([0.1132])\n",
      "Input: tensor([-1.1127])\n",
      "Actual Output: tensor([0.6131])\n",
      "Predicted Output: tensor([0.0684])\n"
     ]
    }
   ],
   "source": [
    "# 예측을 수행할 테스트 데이터를 정의합니다.\n",
    "test_data = [(torch.randn(1), torch.randn(1)) for _ in range(10)]\n",
    "print(test_data)\n",
    "# 모델을 평가 모드로 설정합니다.\n",
    "model.eval()\n",
    "\n",
    "# 각 테스트 데이터에 대한 예측을 수행합니다.\n",
    "with torch.no_grad():  # 그라디언트 계산 비활성화\n",
    "    for x_test, y_test in test_data:\n",
    "        # 입력 데이터를 모델에 전달하여 예측을 수행합니다.\n",
    "        predicted_output = model(x_test)\n",
    "        print(\"Input:\", x_test)\n",
    "        print(\"Actual Output:\", y_test)\n",
    "        print(\"Predicted Output:\", predicted_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "_-u-7Gt_UBIe",
   "metadata": {
    "id": "_-u-7Gt_UBIe"
   },
   "source": [
    "모델평가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "ARr32BLLUD1a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 122670,
     "status": "ok",
     "timestamp": 1715744174721,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "ARr32BLLUD1a",
    "outputId": "307bff9a-a067-46ce-eaa1-cb0bde4ca220"
   },
   "outputs": [],
   "source": [
    "# pip install torchmetrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "XWl_6kAhUK3z",
   "metadata": {
    "id": "XWl_6kAhUK3z"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchmetrics\n",
    "\n",
    "preds = torch.randn(10,5).softmax(dim=-1)\n",
    "target = torch.randint(5, (10,))\n",
    "num_classes = preds.size(1)  # preds 텐서의 마지막 차원의 크기를 가져옴\n",
    "#acc = torchmetrics.functional.accuracy(preds, target)\n",
    "acc = torchmetrics.functional.accuracy(preds, target, task=\"MULTICLASS\", num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "CnGTKD6DUyUF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1715745027026,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "CnGTKD6DUyUF",
    "outputId": "49a104dd-b171-4d49-b9be-6ead0f8ddbe8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on batch 0: 0.20000000298023224\n",
      "Accuracy on batch 1: 0.10000000149011612\n",
      "Accuracy on batch 2: 0.10000000149011612\n",
      "Accuracy on batch 3: 0.0\n",
      "Accuracy on batch 4: 0.10000000149011612\n",
      "Accuracy on batch 5: 0.20000000298023224\n",
      "Accuracy on batch 6: 0.10000000149011612\n",
      "Accuracy on batch 7: 0.20000000298023224\n",
      "Accuracy on batch 8: 0.0\n",
      "Accuracy on batch 9: 0.10000000149011612\n",
      "Accuracy on all data 0.10999999940395355\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchmetrics\n",
    "num_classes = 5\n",
    "metric = torchmetrics.Accuracy(task=\"multiclass\", num_classes=num_classes)\n",
    "#metric = torchmetrics.Accuracy(task=\"multiclass\")\n",
    "\n",
    "n_batches = 10\n",
    "for i in range(n_batches):\n",
    "    preds = torch.randn(10,5).softmax(dim=-1)\n",
    "    target = torch.randint(5, (10,))\n",
    "\n",
    "    acc = metric(preds, target)\n",
    "    print(f\"Accuracy on batch {i}: {acc}\")\n",
    "\n",
    "acc = metric.compute()\n",
    "print(f\"Accuracy on all data {acc}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aS450QIM714i",
   "metadata": {
    "id": "aS450QIM714i"
   },
   "source": [
    "훈련과정 모니터링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "mOuZaGIL7412",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12547,
     "status": "ok",
     "timestamp": 1715771278437,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "mOuZaGIL7412",
    "outputId": "62ea6da7-52ce-4d03-ef13-017b9ebdc8d0"
   },
   "outputs": [],
   "source": [
    "# pip install tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "kNJCuYN78JSd",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "executionInfo": {
     "elapsed": 557,
     "status": "error",
     "timestamp": 1715772152456,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "kNJCuYN78JSd",
    "outputId": "a8ae6cd1-b3f2-467b-cda5-ed9d5cf86bd8"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(\"./book/chap02/tensorboard\")\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    batch_loss = 0.0\n",
    "\n",
    "    for i, (x,y) in enumerate(dataloader):\n",
    "        x,y = x.to(temp.device).float(), y.to(temp.device).float()\n",
    "        outputs = model(x)\n",
    "        loss = criterion(outputs, y)\n",
    "        writer.add_scalar(\"Loss\", loss, epoch)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "42e98bca",
   "metadata": {
    "id": "42e98bca"
   },
   "outputs": [],
   "source": [
    "#2.4 파이토치 코드 맛보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rwU1nKseYS27",
   "metadata": {
    "id": "rwU1nKseYS27"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "44961535",
   "metadata": {
    "id": "44961535"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "4fb364a0",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 77
    },
    "executionInfo": {
     "elapsed": 33709,
     "status": "ok",
     "timestamp": 1715847823458,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "4fb364a0",
    "outputId": "e33dc709-5903-4240-96d5-6aa52bfe8bfa"
   },
   "outputs": [],
   "source": [
    "# from google.colab import files # 데이터 불러오기\n",
    "# file_uploaded=files.upload()   # 데이터 불러오기\n",
    "dataset = pd.read_csv('./book/chap02/data/car_evaluation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "63ea085b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 496,
     "status": "ok",
     "timestamp": 1715847857445,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "63ea085b",
    "outputId": "25949609-9d33-4b31-b5a0-e1f64c6a88f5"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>price</th>\n",
       "      <th>maint</th>\n",
       "      <th>doors</th>\n",
       "      <th>persons</th>\n",
       "      <th>lug_capacity</th>\n",
       "      <th>safety</th>\n",
       "      <th>output</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>small</td>\n",
       "      <td>high</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>low</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>vhigh</td>\n",
       "      <td>vhigh</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>med</td>\n",
       "      <td>med</td>\n",
       "      <td>unacc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   price  maint doors persons lug_capacity safety output\n",
       "0  vhigh  vhigh     2       2        small    low  unacc\n",
       "1  vhigh  vhigh     2       2        small    med  unacc\n",
       "2  vhigh  vhigh     2       2        small   high  unacc\n",
       "3  vhigh  vhigh     2       2          med    low  unacc\n",
       "4  vhigh  vhigh     2       2          med    med  unacc"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "1854b091",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 517
    },
    "executionInfo": {
     "elapsed": 630,
     "status": "ok",
     "timestamp": 1715847866514,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "1854b091",
    "outputId": "35e2b6be-5ad5-4b18-a5df-c3c1e7cbd261"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: ylabel='count'>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig_size = plt.rcParams[\"figure.figsize\"]\n",
    "fig_size[0] = 8\n",
    "fig_size[1] = 6\n",
    "plt.rcParams[\"figure.figsize\"] = fig_size\n",
    "dataset.output.value_counts().plot(kind='pie', autopct='%0.05f%%', colors=['lightblue', 'lightgreen', 'orange', 'pink'], explode=(0.05, 0.05, 0.05,0.05))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "73c82b06",
   "metadata": {
    "id": "73c82b06"
   },
   "outputs": [],
   "source": [
    "categorical_columns = ['price', 'maint', 'doors', 'persons', 'lug_capacity', 'safety']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "281fc4df",
   "metadata": {
    "id": "281fc4df"
   },
   "outputs": [],
   "source": [
    "for category in categorical_columns:\n",
    "    dataset[category] = dataset[category].astype('category')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "c6b735e5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 324,
     "status": "ok",
     "timestamp": 1715848096716,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "c6b735e5",
    "outputId": "f41449be-1574-466a-c17a-ee45dd5828d6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3, 3, 0, 0, 2, 1],\n",
       "       [3, 3, 0, 0, 2, 2],\n",
       "       [3, 3, 0, 0, 2, 0],\n",
       "       [3, 3, 0, 0, 1, 1],\n",
       "       [3, 3, 0, 0, 1, 2],\n",
       "       [3, 3, 0, 0, 1, 0],\n",
       "       [3, 3, 0, 0, 0, 1],\n",
       "       [3, 3, 0, 0, 0, 2],\n",
       "       [3, 3, 0, 0, 0, 0],\n",
       "       [3, 3, 0, 1, 2, 1]], dtype=int8)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "price = dataset['price'].cat.codes.values\n",
    "maint = dataset['maint'].cat.codes.values\n",
    "doors = dataset['doors'].cat.codes.values\n",
    "persons = dataset['persons'].cat.codes.values\n",
    "lug_capacity = dataset['lug_capacity'].cat.codes.values\n",
    "safety = dataset['safety'].cat.codes.values\n",
    "\n",
    "categorical_data = np.stack([price, maint, doors, persons, lug_capacity, safety], 1)\n",
    "categorical_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "11ea6d73",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 320,
     "status": "ok",
     "timestamp": 1715848214116,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "11ea6d73",
    "outputId": "c797995e-fdbf-421f-9930-8763c919ab0e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3, 3, 0, 0, 2, 1],\n",
       "        [3, 3, 0, 0, 2, 2],\n",
       "        [3, 3, 0, 0, 2, 0],\n",
       "        [3, 3, 0, 0, 1, 1],\n",
       "        [3, 3, 0, 0, 1, 2],\n",
       "        [3, 3, 0, 0, 1, 0],\n",
       "        [3, 3, 0, 0, 0, 1],\n",
       "        [3, 3, 0, 0, 0, 2],\n",
       "        [3, 3, 0, 0, 0, 0],\n",
       "        [3, 3, 0, 1, 2, 1]])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_data = torch.tensor(categorical_data, dtype=torch.int64)\n",
    "categorical_data[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e765bcab",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 347,
     "status": "ok",
     "timestamp": 1715848236754,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "e765bcab",
    "outputId": "eec174b9-b68c-4edd-af44-43cf89394ad5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1728, 6])\n",
      "torch.Size([6912])\n"
     ]
    }
   ],
   "source": [
    "outputs = pd.get_dummies(dataset.output)\n",
    "outputs = outputs.values\n",
    "outputs = torch.tensor(outputs).flatten()\n",
    "\n",
    "print(categorical_data.shape)\n",
    "print(outputs.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "828e0711",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 353,
     "status": "ok",
     "timestamp": 1715779105896,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "828e0711",
    "outputId": "ae0b1728-a854-430a-ab0e-1d62a25d0032"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(4, 2), (4, 2), (4, 2), (3, 2), (3, 2), (3, 2)]\n"
     ]
    }
   ],
   "source": [
    "categorical_column_sizes = [len(dataset[column].cat.categories) for column in categorical_columns]\n",
    "categorical_embedding_sizes = [(col_size, min(50, (col_size+1)//2)) for col_size in categorical_column_sizes]\n",
    "print(categorical_embedding_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "de38aa0b",
   "metadata": {
    "id": "de38aa0b"
   },
   "outputs": [],
   "source": [
    "total_records = 1728\n",
    "test_records = int(total_records * .2)\n",
    "\n",
    "categorical_train_data = categorical_data[:total_records-test_records]\n",
    "categorical_test_data = categorical_data[total_records-test_records:total_records]\n",
    "train_outputs = outputs[:total_records-test_records]\n",
    "test_outputs = outputs[total_records-test_records:total_records]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "46eb162b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 298,
     "status": "ok",
     "timestamp": 1715779120682,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "46eb162b",
    "outputId": "6204c0ee-5140-46fe-99ce-b25e67c871de"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1383\n",
      "1383\n",
      "345\n",
      "345\n"
     ]
    }
   ],
   "source": [
    "print(len(categorical_train_data))\n",
    "print(len(train_outputs))\n",
    "print(len(categorical_test_data))\n",
    "print(len(test_outputs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2eaa67ca",
   "metadata": {
    "id": "2eaa67ca"
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, embedding_size, output_size, layers, p=0.4):\n",
    "        super().__init__()\n",
    "        self.all_embeddings = nn.ModuleList([nn.Embedding(ni, nf) for ni, nf in embedding_size])\n",
    "        self.embedding_dropout = nn.Dropout(p)\n",
    "\n",
    "        all_layers = []\n",
    "        num_categorical_cols = sum((nf for ni, nf in embedding_size))\n",
    "        input_size = num_categorical_cols\n",
    "\n",
    "        for i in layers:\n",
    "            all_layers.append(nn.Linear(input_size, i))\n",
    "            all_layers.append(nn.ReLU(inplace=True))\n",
    "            all_layers.append(nn.BatchNorm1d(i))\n",
    "            all_layers.append(nn.Dropout(p))\n",
    "            input_size = i\n",
    "\n",
    "        all_layers.append(nn.Linear(layers[-1], output_size))\n",
    "        self.layers = nn.Sequential(*all_layers)\n",
    "\n",
    "    def forward(self, x_categorical):\n",
    "        embeddings = []\n",
    "        for i,e in enumerate(self.all_embeddings):\n",
    "            embeddings.append(e(x_categorical[:,i]))\n",
    "        x = torch.cat(embeddings, 1)\n",
    "        x = self.embedding_dropout(x)\n",
    "        x = self.layers(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "4909ff0e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 307,
     "status": "ok",
     "timestamp": 1715779161756,
     "user": {
      "displayName": "Bonghee Hong",
      "userId": "17805293653427923937"
     },
     "user_tz": -540
    },
    "id": "4909ff0e",
    "outputId": "7ae94821-419f-4147-b4b9-5d761bcb3320"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (all_embeddings): ModuleList(\n",
      "    (0-2): 3 x Embedding(4, 2)\n",
      "    (3-5): 3 x Embedding(3, 2)\n",
      "  )\n",
      "  (embedding_dropout): Dropout(p=0.4, inplace=False)\n",
      "  (layers): Sequential(\n",
      "    (0): Linear(in_features=12, out_features=200, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): BatchNorm1d(200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (3): Dropout(p=0.4, inplace=False)\n",
      "    (4): Linear(in_features=200, out_features=100, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): BatchNorm1d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): Dropout(p=0.4, inplace=False)\n",
      "    (8): Linear(in_features=100, out_features=50, bias=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): Dropout(p=0.4, inplace=False)\n",
      "    (12): Linear(in_features=50, out_features=4, bias=True)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Model(categorical_embedding_sizes, 4, [200,100,50], p=0.4)\n",
    "# output_data = model(input_data)# forward() 메소드가 실행\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "301d59a6",
   "metadata": {
    "id": "301d59a6"
   },
   "outputs": [],
   "source": [
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "KyuD2fLKM7Px",
   "metadata": {
    "id": "KyuD2fLKM7Px"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "기울기가 0인 x: -0.4999999999999997\n",
      "해당 지점에서의 y 값: 5.75\n"
     ]
    }
   ],
   "source": [
    "# 주어진 함수 정의\n",
    "def func(x):\n",
    "    return 5 * x ** 2 + 5 * x + 7\n",
    "\n",
    "# 도함수(미분) 계산\n",
    "def derivative(x):\n",
    "    return 10 * x + 5\n",
    "\n",
    "# 경사 하강법을 사용하여 기울기가 0인 지점 찾기\n",
    "def gradient_descent(learning_rate, initial_x, epochs):\n",
    "    x = initial_x\n",
    "    for _ in range(epochs):\n",
    "        gradient = derivative(x)\n",
    "        x = x - learning_rate * gradient\n",
    "    return x\n",
    "\n",
    "# 학습률, 초기값, 반복 횟수 설정\n",
    "learning_rate = 0.01\n",
    "initial_x = 0.0\n",
    "epochs = 1000\n",
    "\n",
    "# 경사 하강법 적용하여 기울기가 0인 지점 찾기\n",
    "optimal_x = gradient_descent(learning_rate, initial_x, epochs)\n",
    "optimal_y = func(optimal_x)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"기울기가 0인 x:\", optimal_x)\n",
    "print(\"해당 지점에서의 y 값:\", optimal_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "3d5c313f",
   "metadata": {
    "id": "3d5c313f"
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "56492e5b",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "56492e5b",
    "outputId": "51e99adc-0975-422f-eb01-20719c4e3bcd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:   1 loss: 1.59662950\n",
      "epoch:  26 loss: 1.37881255\n",
      "epoch:  51 loss: 1.27624261\n",
      "epoch:  76 loss: 1.18256819\n",
      "epoch: 101 loss: 1.05669427\n",
      "epoch: 126 loss: 0.93214267\n",
      "epoch: 151 loss: 0.82580072\n",
      "epoch: 176 loss: 0.74351668\n",
      "epoch: 201 loss: 0.68590319\n",
      "epoch: 226 loss: 0.64794219\n",
      "epoch: 251 loss: 0.62431389\n",
      "epoch: 276 loss: 0.61999279\n",
      "epoch: 301 loss: 0.61436224\n",
      "epoch: 326 loss: 0.60385400\n",
      "epoch: 351 loss: 0.59320533\n",
      "epoch: 376 loss: 0.58794475\n",
      "epoch: 401 loss: 0.58836216\n",
      "epoch: 426 loss: 0.58107233\n",
      "epoch: 451 loss: 0.58438200\n",
      "epoch: 476 loss: 0.57783592\n",
      "epoch: 500 loss: 0.5703202486\n"
     ]
    }
   ],
   "source": [
    "epochs = 500\n",
    "aggregated_losses = []\n",
    "train_outputs = train_outputs.to(device=device, dtype=torch.int64)\n",
    "for i in range(epochs):\n",
    "    i += 1\n",
    "    y_pred = model(categorical_train_data).to(device)\n",
    "    single_loss = loss_function(y_pred, train_outputs)\n",
    "    aggregated_losses.append(single_loss)\n",
    "\n",
    "    if i%25 == 1:\n",
    "        print(f'epoch: {i:3} loss: {single_loss.item():10.8f}')\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    single_loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(f'epoch: {i:3} loss: {single_loss.item():10.10f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "fd2f1035",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fd2f1035",
    "outputId": "130d32d1-a203-4208-e327-eabb367e46fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss: 0.55571860\n"
     ]
    }
   ],
   "source": [
    "test_outputs = test_outputs.to(device=device, dtype=torch.int64)\n",
    "with torch.no_grad():\n",
    "    y_val = model(categorical_test_data).to(device)\n",
    "    loss = loss_function(y_val, test_outputs)\n",
    "print(f'Loss: {loss:.8f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "6735f451",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6735f451",
    "outputId": "cdbe9174-23c8-43c2-e82d-e71f7607d11f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.8694,  1.5345, -3.1620, -3.2550],\n",
      "        [ 2.7249,  1.5456, -2.4184, -2.1944],\n",
      "        [ 3.1923,  1.9411, -3.8894, -3.6226],\n",
      "        [ 2.2376,  1.2550, -3.6849, -3.6618],\n",
      "        [ 2.7793,  1.5858, -3.7518, -3.5167]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "print(y_val[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "5acf59f2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5acf59f2",
    "outputId": "f9a2ec26-2e2c-419c-d959-9c720b90bec4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "y_val = np.argmax(y_val.cpu().numpy(), axis=1)\n",
    "print(y_val[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a7e16502",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a7e16502",
    "outputId": "91fbee59-4b85-4bbc-9854-25da410bcd55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[257   2]\n",
      " [ 85   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.99      0.86       259\n",
      "           1       0.33      0.01      0.02        86\n",
      "\n",
      "    accuracy                           0.75       345\n",
      "   macro avg       0.54      0.50      0.44       345\n",
      "weighted avg       0.65      0.75      0.65       345\n",
      "\n",
      "0.7478260869565218\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "test_outputs=test_outputs.cpu().numpy()\n",
    "print(confusion_matrix(test_outputs,y_val))\n",
    "print(classification_report(test_outputs,y_val))\n",
    "print(accuracy_score(test_outputs, y_val))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Vzrg4SeHdw65",
   "metadata": {
    "id": "Vzrg4SeHdw65"
   },
   "source": [
    "구글링: 2023.04.18 주피터노트북 VSCode 연동, 가상환경 만들기, GPU사용 환경 세팅(에러 해결 방법), 차유빈·2023년 4월 20일"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "torch_book",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
